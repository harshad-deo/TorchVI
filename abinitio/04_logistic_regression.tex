\documentclass[10pt]{article}
\usepackage[a4paper, margin=1in]{geometry}
\usepackage{hyperref}
\usepackage{setspace}
\usepackage{amsmath}
\usepackage{eufrak}
\usepackage{amssymb}
\usepackage{mathtools}

\newcommand{\defeq}{\vcentcolon=}

\title{Ab'Initio ADVI \\ Logistic Regression}
\author{Harshad Deo \\ 
  \href{mailto:harshad@moreficent.com}{harshad@moreficent.com} \\ 
  \href{mailto:harshad@simianquant.com}{harshad@simianquant.com}
}
\date{}

\setlength{\parindent}{0cm}

\hypersetup{
  colorlinks,
  citecolor=blue,
  filecolor=blue,
  linkcolor=blue,
  urlcolor=blue
}
  
\setlength{\parskip}{\baselineskip}%
  
  
\begin{document}
  
\maketitle

Consider a Bernoulli random variable with a success probability given by the logit of a univariate linear model with 
Gaussian priors on the regression coefficients. Formally,

\begin{align*}
  Y &\sim \text{Bernoulli}\Big(\frac{1}{1 + exp(-(\theta_0 + \theta_1 X))}\Big) \\
  \theta_0, \theta_1 &\sim \mathcal{N}(0, 0.5)
\end{align*}

$\theta_0$ and $\theta_1$ are unconstrained, therefore the domain transforms are given by identity functions:

\begin{align*}
  \zeta_0 &= T_0(\theta_0) = \theta_0 \\
  \zeta_1 &= T_0(\theta_1) = \theta_1 \\
  \theta_0 &= T^{-1}_0(\zeta_0) = \zeta_0 \\
  \theta_1 &= T^{-1}_1(\zeta_1) = \zeta_1
\end{align*}

Therefore the log determinant of the jacobian of the inverse transform evaluates to 0. Approximating $\zeta_i$ with a 
Gaussian distribution with mean $\mu_i$ and scale $\exp(\omega_i)$, the approximated variational space is given by:

\begin{equation*}
  \Phi = \{\mu_i, \omega_i\}, i = 0, 1 = \mathbb{R}^4
\end{equation*}


Given the variational approximation, the elliptical standardization is given by:

\begin{align*}
  \eta_i &= S_{\phi}(\zeta_i) = \frac{\zeta_i - \mu_i}{\exp(\omega_i)}, i = 0, 1 \\
  \zeta_i &= S_{\phi}^{-1}(\eta_i) = \mu_i + \eta_i \exp(\omega_i)
\end{align*}


Therefore the objective function is given by:

\begin{align*}
  \mu_i^*, \omega_i^* &= \underset{\mu_i, \omega_i}{\text{argmax}}\,\mathbb{E}_\eta\big[\log p(x, \theta_0, \theta_1) \big] + \omega_0 + \omega_1 \\
  &= \underset{\mu_i, \omega_i}{\text{argmax}}\,\mathbb{E}_\eta\big[\log p(x | \theta_0, \theta_1) + \log p(\theta_0, \theta_1) \big] + \omega_0 + \omega_1 \\
  &= \underset{\mu_i, \omega_i}{\text{argmax}}\,\mathbb{E}_\eta\big[\log p(x | \theta_0, \theta_1) + \log p(\theta_0) + \log p (\theta_1) \big] + \omega_0 + \omega_1
\end{align*}

\end{document}
